{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Author**          | **Roll No**   | **Version** |\n",
    "|---------------------|----------------|--------------|\n",
    "| Vinayak Rana        | 24210114       | 1.0          |\n",
    "\n",
    "#### Introduction\n",
    "In this notebook we will scrap data from freely available (open access) springer articles and research papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pdfplumber\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://link.springer.com/search?package=openaccess&facet-language=%22En%22')\n",
    "page = BeautifulSoup(response.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_body = page.find(class_='content-item-list')\n",
    "x=page.find('a',class_='next')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('book_results_springer.csv', 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('book_results_springer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text file download successful for Lone Parenthood in the Life Course.txt.\n",
      "Text file download successful for The European Blood and Marrow Transplantation Textbook for Nurses.txt.\n",
      "Text file download successful for Bisociative Knowledge Discovery.txt.\n",
      "Text file download successful for Renewing Local Planning to Face Climate Change in the Tropics.txt.\n",
      "Text file download successful for Care in Healthcare.txt.\n",
      "Text file download successful for Applying the Kaizen in Africa.txt.\n",
      "Text file download successful for Designing Urban Food Policies.txt.\n",
      "Text file download successful for Surgical Ophthalmic Oncology.txt.\n",
      "Text file download successful for Connecting Mathematics and Mathematics Education.txt.\n",
      "Text file download successful for Foundations of Software Science and Computation Structures.txt.\n",
      "Text file download successful for Subsidiaritätsgrundsatz und Tatsachenfeststellung unter der Europäischen Menschenrechtskonvention.txt.\n",
      "Text file download successful for Energy in Africa.txt.\n",
      "Text file download successful for Accounting and Statistical Analyses for Sustainable Development.txt.\n",
      "Text file download successful for United Nations Peace Operations in a Changing Global Order.txt.\n",
      "Text file download successful for Knowing the Salween River: Resource Politics of a Contested Transboundary River.txt.\n",
      "Text file download successful for Pre-Field Screening Protocols for Heat-Tolerant Mutants in Rice.txt.\n",
      "Text file download successful for Reversible Computation: Extending Horizons of Computing.txt.\n",
      "Text file download successful for Linked Open Data -- Creating Knowledge Out of Interlinked Data.txt.\n",
      "Text file download successful for China's Energy Revolution in the Context of the Global Energy Transition.txt.\n",
      "Text file download successful for Inside Asylum Bureaucracy: Organizing Refugee Status Determination in Austria.txt.\n",
      "Text file download successful for The Amazing Journey of Reason.txt.\n",
      "Text file download successful for Education and Development in Colonial and Postcolonial Africa.txt.\n",
      "Text file download successful for Messung von Ressourceneffizienz mit der ESSENZ-Methode.txt.\n",
      "Text file download successful for Rational Cybersecurity for Business.txt.\n",
      "Text file download successful for IEA International Civic and Citizenship Education Study 2016 Assessment Framework.txt.\n",
      "Text file download successful for Improving a Country’s Education.txt.\n",
      "Text file download successful for High-Performance Modelling and Simulation for Big Data Applications.txt.\n",
      "Text file download successful for Traditions in German-Speaking Mathematics Education Research.txt.\n",
      "Text file download successful for Spanish Economic Growth, 1850–2015.txt.\n",
      "Text file download successful for From War to Peace in the Balkans, the Middle East and Ukraine.txt.\n",
      "Text file download successful for Advances in Wheat Genetics: From Genome to Field.txt.\n",
      "Text file download successful for Supercomputing Frontiers.txt.\n",
      "Text file download successful for Managing Protected Areas in Central and Eastern Europe Under Climate Change.txt.\n",
      "Text file download successful for The Plant Stem.txt.\n",
      "Text file download successful for Anisotropy Across Fields and Scales.txt.\n",
      "Text file download successful for Foundations of Software Science and Computation Structures.txt.\n",
      "Text file download successful for European Cultural Diplomacy and Arab Christians in Palestine, 1918–1948.txt.\n",
      "Text file download successful for Inter-group Relations and Migrant Integration in European Cities.txt.\n",
      "Text file download successful for Environmental Governance of the Baltic Sea.txt.\n",
      "Text file download successful for Sustainable Rice Straw Management.txt.\n",
      "Text file download successful for System-Aufstellungen und ihre naturwissenschaftliche Begründung.txt.\n",
      "Text file download successful for R.J. Rummel: An Assessment of His Many Contributions.txt.\n",
      "Text file download successful for Saving for Development.txt.\n",
      "Text file download successful for AiREAS: Sustainocracy for a Healthy City.txt.\n",
      "Text file download successful for Quantization on Nilpotent Lie Groups.txt.\n",
      "Text file download successful for VR Technologies in Cultural Heritage.txt.\n",
      "Text file download successful for Intertwingled.txt.\n",
      "Text file download successful for Disasters: Core Concepts and Ethical Theories.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring (part of) ToUnicode map because the PDF data does not conform to the format. This could result in (cid) values in the output. The start and end byte have different lengths.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text file download successful for Expatriates und freiwilliges Engagement in der Schweiz.txt.\n",
      "Text file download successful for A History of Male Psychological Disorders in Britain, 1945–1980.txt.\n",
      "Text file download successful for Representations of Transnational Human Trafficking.txt.\n",
      "Text file download successful for Managing the Complexity of Critical Infrastructures.txt.\n",
      "Text file download successful for Counteracting Urban Heat Island Effects in a Global Climate Change Scenario.txt.\n",
      "Text file download successful for Leveraging Data Science for Global Health.txt.\n",
      "Text file download successful for Theoretical and Practical Advances in Computer-based Educational Measurement.txt.\n",
      "Text file download successful for S-BPM Illustrated.txt.\n",
      "Text file download successful for Heterogeneity, High Performance Computing, Self-Organization and the Cloud.txt.\n",
      "Text file download successful for Problem Solving in Mathematics Education.txt.\n",
      "Text file download successful for Promoting Active Citizenship.txt.\n",
      "Text file download successful for Charting Spiritual Care.txt.\n",
      "Text file download successful for Weißbuch Gelenkersatz.txt.\n",
      "Text file download successful for On the path to AI.txt.\n",
      "Text file download successful for Moral Reasoning at Work: Rethinking Ethics in Organizations.txt.\n",
      "Text file download successful for Teaching Tolerance in a Globalized World.txt.\n",
      "Text file download successful for Knowledge and Institutions.txt.\n",
      "Failed to download PDF from https://link.springer.com/content/pdf/10.1007/978-3-319-13719-3.pdf. Status code: 400\n",
      "Text file download successful for Service Design Capabilities.txt.\n",
      "Text file download successful for Global History and New Polycentric Approaches.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7ff7f27d3e50>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/HDFS1/language_nlp/english_nlp_team17/Assignment1/.venv/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pdf_response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     38\u001b[0m     pdf_content \u001b[38;5;241m=\u001b[39m pdf_response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m---> 39\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mpdf_to_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[1;32m     42\u001b[0m     filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(text_output_dir, filename)\n",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m, in \u001b[0;36mpdf_to_text\u001b[0;34m(pdf_content)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pdfplumber\u001b[38;5;241m.\u001b[39mopen(BytesIO(pdf_content)) \u001b[38;5;28;01mas\u001b[39;00m pdf:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pdf\u001b[38;5;241m.\u001b[39mpages:\n\u001b[0;32m----> 7\u001b[0m         text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[0;32m/mnt/HDFS1/language_nlp/english_nlp_team17/Assignment1/.venv/lib/python3.8/site-packages/pdfplumber/page.py:538\u001b[0m, in \u001b[0;36mPage.extract_text\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m--> 538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_textmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtuplify_list_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mas_string\n",
      "File \u001b[0;32m/mnt/HDFS1/language_nlp/english_nlp_team17/Assignment1/.venv/lib/python3.8/site-packages/pdfplumber/page.py:515\u001b[0m, in \u001b[0;36mPage._get_textmap\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m     defaults\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout_height\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight})\n\u001b[1;32m    514\u001b[0m full_kwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefaults, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m--> 515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mchars_to_textmap(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchars\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_kwargs)\n",
      "File \u001b[0;32m/mnt/HDFS1/language_nlp/english_nlp_team17/Assignment1/.venv/lib/python3.8/site-packages/pdfplumber/container.py:52\u001b[0m, in \u001b[0;36mContainer.chars\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchars\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T_obj_list:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchar\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n",
      "File \u001b[0;32m/mnt/HDFS1/language_nlp/english_nlp_team17/Assignment1/.venv/lib/python3.8/site-packages/pdfplumber/page.py:347\u001b[0m, in \u001b[0;36mPage.objects\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_objects\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objects\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objects: Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objects\n",
      "File \u001b[0;32m/mnt/HDFS1/language_nlp/english_nlp_team17/Assignment1/.venv/lib/python3.8/site-packages/pdfplumber/page.py:451\u001b[0m, in \u001b[0;36mPage.parse_objects\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_objects\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list]:\n\u001b[1;32m    450\u001b[0m     objects: Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_layout_objects(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayout\u001b[49m\u001b[38;5;241m.\u001b[39m_objs):\n\u001b[1;32m    452\u001b[0m         kind \u001b[38;5;241m=\u001b[39m obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m kind \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manno\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/mnt/HDFS1/language_nlp/english_nlp_team17/Assignment1/.venv/lib/python3.8/site-packages/pdfplumber/page.py:277\u001b[0m, in \u001b[0;36mPage.layout\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m device \u001b[38;5;241m=\u001b[39m PDFPageAggregatorWithMarkedContent(\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpdf\u001b[38;5;241m.\u001b[39mrsrcmgr,\n\u001b[1;32m    273\u001b[0m     pageno\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpage_number,\n\u001b[1;32m    274\u001b[0m     laparams\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpdf\u001b[38;5;241m.\u001b[39mlaparams,\n\u001b[1;32m    275\u001b[0m )\n\u001b[1;32m    276\u001b[0m interpreter \u001b[38;5;241m=\u001b[39m PDFPageInterpreter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpdf\u001b[38;5;241m.\u001b[39mrsrcmgr, device)\n\u001b[0;32m--> 277\u001b[0m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout: LTPage \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mget_result()\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout\n",
      "File \u001b[0;32m/mnt/HDFS1/language_nlp/english_nlp_team17/Assignment1/.venv/lib/python3.8/site-packages/pdfminer/pdfinterp.py:997\u001b[0m, in \u001b[0;36mPDFPageInterpreter.process_page\u001b[0;34m(self, page)\u001b[0m\n\u001b[1;32m    995\u001b[0m     ctm \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39mx0, \u001b[38;5;241m-\u001b[39my0)\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mbegin_page(page, ctm)\n\u001b[0;32m--> 997\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mend_page(page)\n\u001b[1;32m    999\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/HDFS1/language_nlp/english_nlp_team17/Assignment1/.venv/lib/python3.8/site-packages/pdfminer/pdfinterp.py:1016\u001b[0m, in \u001b[0;36mPDFPageInterpreter.render_contents\u001b[0;34m(self, resources, streams, ctm)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_resources(resources)\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_state(ctm)\n\u001b[0;32m-> 1016\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstreams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/HDFS1/language_nlp/english_nlp_team17/Assignment1/.venv/lib/python3.8/site-packages/pdfminer/pdfinterp.py:1027\u001b[0m, in \u001b[0;36mPDFPageInterpreter.execute\u001b[0;34m(self, streams)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1027\u001b[0m         (_, obj) \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnextobject\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1028\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m PSEOF:\n\u001b[1;32m   1029\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/HDFS1/language_nlp/english_nlp_team17/Assignment1/.venv/lib/python3.8/site-packages/pdfminer/psparser.py:656\u001b[0m, in \u001b[0;36mPSStackParser.nextobject\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token, PSKeyword):\n\u001b[1;32m    653\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    654\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_keyword: pos=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m, token=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m, stack=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, pos, token, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurstack\n\u001b[1;32m    655\u001b[0m     )\n\u001b[0;32m--> 656\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_keyword\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    658\u001b[0m     log\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    659\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown token: pos=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m, token=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m, stack=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    660\u001b[0m         pos,\n\u001b[1;32m    661\u001b[0m         token,\n\u001b[1;32m    662\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurstack,\n\u001b[1;32m    663\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text_output_dir = 'Data/springer_data/'\n",
    "\n",
    "def pdf_to_text(pdf_content):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(BytesIO(pdf_content)) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "flag=False\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    if row['Item Title'] == 'Programming for Computations  - MATLAB/Octave':\n",
    "        flag = True\n",
    "        continue\n",
    "        \n",
    "    if not flag:\n",
    "        continue\n",
    "\n",
    "\n",
    "    link = row['URL']\n",
    "    text_name = row['Item Title']\n",
    "\n",
    "    try:\n",
    "        response = requests.get(link)\n",
    "        response.raise_for_status()  \n",
    "\n",
    "        page = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        download_button = page.find('a', class_='u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link')\n",
    "        \n",
    "        if download_button and 'href' in download_button.attrs:\n",
    "            pdf_url = 'https://link.springer.com' + download_button['href']\n",
    "            \n",
    "            pdf_response = requests.get(pdf_url)\n",
    "            \n",
    "            if pdf_response.status_code == 200:\n",
    "                pdf_content = pdf_response.content\n",
    "                text = pdf_to_text(pdf_content)\n",
    "                \n",
    "                filename = f\"{text_name}.txt\"  \n",
    "                filepath = os.path.join(text_output_dir, filename)\n",
    "                \n",
    "                with open(filepath, 'w', encoding='utf-8') as file:\n",
    "                    file.write(text)\n",
    "                print(f'Text file download successful for {filename}.')\n",
    "            else:\n",
    "                print(f'Failed to download PDF from {pdf_url}. Status code: {pdf_response.status_code}')\n",
    "        else:\n",
    "            print(f'Download button not found for {link}')\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        print(f'Error during request: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
