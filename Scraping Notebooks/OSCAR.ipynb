{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Author**          | **Roll No**   | **Version** |\n",
    "|---------------------|----------------|--------------|\n",
    "|Kaloori Shiva Prasad       | 24250041      | 1.0          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_dir = \"/mnt/HDFS1/language_nlp/english_nlp_team17/Assignment1/Shiva/Data/Oscar_Texts\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = load_dataset(\"oscar\", \"unshuffled_deduplicated_en\", split=\"train\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: ['id', 'text'],\n",
       "    n_shards: 670\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = 0\n",
    "size_limit = 20 * (1024 ** 3)  \n",
    "dataset_info = dataset.info\n",
    "print(dataset_info)\n",
    "\n",
    "\n",
    "for i, sample in enumerate(dataset):\n",
    "    text = sample[\"text\"]\n",
    "    text_size = len(text.encode(\"utf-8\"))\n",
    "    print(f\"Article {i}, Size: {text_size} bytes, Total_size: {total_size/(1024 ** 3)}\")\n",
    "    \n",
    "    \n",
    "    if total_size + text_size > size_limit:\n",
    "        print(\"Size limit reached. Stopping.\")\n",
    "        break\n",
    "\n",
    "    \n",
    "    file_path = f\"{output_dir}/oscar_text_article_{i + 1}.txt\"\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        f_out.write(text)\n",
    "\n",
    "    \n",
    "    total_size += text_size\n",
    "    \n",
    "\n",
    "print(f\"Downloaded {total_size / (1024 ** 3):.2f} GB of data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
