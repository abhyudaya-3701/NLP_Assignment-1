{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Author**          | **Roll No**   | **Version** |\n",
    "|---------------------|----------------|--------------|\n",
    "| Kaloori Shiva Prasad       | 24250041      | 1.0          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import zipfile\n",
    "import os\n",
    "import re\n",
    "\n",
    "base_url = \"https://www.msubs.net\"\n",
    "\n",
    "\n",
    "def download_txt(download_url):\n",
    "    response = requests.get(download_url)\n",
    "    response.raise_for_status()  \n",
    "\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "   \n",
    "    script_tag = soup.find('script', string=re.compile(r's2'))\n",
    "\n",
    "    if script_tag:\n",
    "        script_content = script_tag.string\n",
    "        print(\"JavaScript content found in the HTML.\")\n",
    "\n",
    "        \n",
    "        s1_match = re.search(r\"var s1\\s*=\\s*'(.+?)';\", script_content)\n",
    "        s2_match = re.search(r\"var s2\\s*=\\s*'(.+?)';\", script_content)\n",
    "        s3_match = re.search(r\"var s3\\s*=\\s*'(.+?)';\", script_content)\n",
    "        s4_match = re.search(r\"var s4\\s*=\\s*'(.+?)';\", script_content)\n",
    "\n",
    "        if s1_match and s2_match and s3_match and s4_match:\n",
    "            s1 = s1_match.group(1)\n",
    "            s2 = s2_match.group(1)\n",
    "            s3 = s3_match.group(1)\n",
    "            s4 = s4_match.group(1)\n",
    "\n",
    "            \n",
    "            constructed_url = f\"{s1}{s2}{s3}{s4}\".replace(\" \", \"%20\")\n",
    "\n",
    "            \n",
    "            if not constructed_url.startswith(\"http\"):\n",
    "                constructed_url = f\"https://www.msubs.net/{constructed_url}\"\n",
    "\n",
    "            print(f\"Constructed ZIP file download URL: {constructed_url}\")\n",
    "\n",
    "            \n",
    "            zip_file_response = requests.get(constructed_url)\n",
    "            zip_file_response.raise_for_status()\n",
    "\n",
    "            \n",
    "            zip_filename = s4 \n",
    "            with open(zip_filename, 'wb') as f:\n",
    "                f.write(zip_file_response.content)\n",
    "            print(f\"ZIP file '{zip_filename}' downloaded successfully.\")\n",
    "\n",
    "            \n",
    "            extract_folder = '/mnt/HDFS1/language_nlp/english_nlp_team17/Assignment1/Data_Shiva/Subtitles'\n",
    "            os.makedirs(extract_folder, exist_ok=True)\n",
    "\n",
    "            \n",
    "            try:\n",
    "                with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "                    zip_ref.testzip()  \n",
    "                    zip_ref.extractall(extract_folder)\n",
    "                print(\"ZIP file extracted successfully.\")\n",
    "\n",
    "                \n",
    "                for file in os.listdir(extract_folder):\n",
    "                    if file.endswith('.srt'):\n",
    "                        srt_file_path = os.path.join(extract_folder, file)\n",
    "                        txt_file_path = srt_file_path.replace('.srt', '.txt')\n",
    "                        \n",
    "                        srt_to_txt(srt_file_path, txt_file_path)\n",
    "                        \n",
    "                        \n",
    "                        os.remove(srt_file_path)\n",
    "                        print(f\"Deleted {srt_file_path} after conversion.\")\n",
    "                \n",
    "                \n",
    "                os.remove(zip_filename)\n",
    "                print(f\"ZIP file '{zip_filename}' deleted.\")\n",
    "\n",
    "            except zipfile.BadZipFile:\n",
    "                print(\"The downloaded file is not a valid ZIP file.\")\n",
    "        else:\n",
    "            print(\"Failed to extract 's1', 's2', 's3', or 's4' from the script.\")\n",
    "    else:\n",
    "        print(\"No JavaScript content with 's2' found on the page.\")\n",
    "\n",
    "\n",
    "def srt_to_txt(srt_file_path, txt_file_path):\n",
    "    \n",
    "    encodings = ['utf-8', 'iso-8859-1', 'cp1252']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(srt_file_path, 'r', encoding=encoding) as srt_file:\n",
    "                with open(txt_file_path, 'w', encoding='utf-8') as txt_file:\n",
    "                    for line in srt_file:\n",
    "                        \n",
    "                        if '-->' in line or re.match(r'^\\d+$', line.strip()):\n",
    "                            continue\n",
    "                        \n",
    "                        txt_file.write(line)\n",
    "            print(f\"Subtitle converted to text and saved as {txt_file_path}\")\n",
    "            break\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Failed to decode {srt_file_path} with encoding {encoding}. Trying next encoding.\")\n",
    "    \n",
    "\n",
    "for i in range(1, 421):  \n",
    "    download_url = f\"https://www.msubs.net//download-{i}.html\"\n",
    "    download_txt(download_url)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
