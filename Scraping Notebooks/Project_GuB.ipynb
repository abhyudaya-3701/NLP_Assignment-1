{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Author**          | **Roll No**   | **Version** |\n",
    "|---------------------|----------------|--------------|\n",
    "| Kaloori Shiva Prasad        | 24250041     | 1.0          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time  \n",
    "from requests.exceptions import ChunkedEncodingError, ConnectionError\n",
    "\n",
    "\n",
    "base_url = 'https://www.gutenberg.org'\n",
    "\n",
    "def get_book_urls_from_author(letter):\n",
    "    response = requests.get(f'{base_url}/browse/authors/{letter}')\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    book_urls = []\n",
    "    for li in soup.find_all('li', class_='pgdbetext'):\n",
    "        a_tag = li.find('a', href=True)\n",
    "        if a_tag:\n",
    "            book_url = base_url + a_tag['href']\n",
    "            if '(English)' in li.text: \n",
    "                book_urls.append(book_url)\n",
    "    print(f'{letter} : {len(book_urls)}')\n",
    "    return book_urls\n",
    "\n",
    "def get_book_id(book_url):\n",
    "   \n",
    "    return book_url.strip('/').split('/')[-1]\n",
    "\n",
    "def download_book(book_url, save_dir='mnt/HDFS1/language_nlp/english_nlp_team17/Assignment1/Data_Shiva/Project Gutenberg Data'):\n",
    "    os.makedirs(save_dir, exist_ok=True)  \n",
    "    base_text_url = 'https://www.gutenberg.org/cache/epub'\n",
    "    book_id = get_book_id(book_url)\n",
    "    download_url = f'{base_text_url}/{book_id}/pg{book_id}.txt'\n",
    "    \n",
    "    try:\n",
    "        book_response = requests.get(download_url, stream=True) \n",
    "        if book_response.status_code == 200:  \n",
    "            \n",
    "            file_path = os.path.join(save_dir, f'{book_id}.txt')\n",
    "            with open(file_path, 'wb') as file:\n",
    "                for chunk in book_response.iter_content(chunk_size=1024):\n",
    "                    if chunk:  \n",
    "                        file.write(chunk)\n",
    "            # print(f\"Successfully downloaded {book_id}.txt\")\n",
    "        else:\n",
    "            print(f\"Failed to download from {download_url}. Status code: {book_response.status_code}\")\n",
    "    \n",
    "    except (ChunkedEncodingError, ConnectionError) as e:\n",
    "        print(f\"Error occurred while downloading {download_url}: {e}. Skipping to next.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error occurred: {e}. Skipping to next.\")\n",
    "\n",
    "\n",
    "# def download_book(book_url, save_dir='Project Gutenberg Data'):\n",
    "#     os.makedirs(save_dir, exist_ok=True)  # Create the directory if it does not exist\n",
    "#     base_text_url = 'https://www.gutenberg.org/cache/epub'\n",
    "#     book_id = get_book_id(book_url)\n",
    "#     download_url = f'{base_text_url}/{book_id}/pg{book_id}.txt'\n",
    "#     book_response = requests.get(download_url)\n",
    "#     if book_response.status_code == 200:  # Check if the download is successful\n",
    "#         # Save the book text to a file\n",
    "#         file_path = os.path.join(save_dir, f'{book_id}.txt')\n",
    "#         with open(file_path, 'wb') as file:\n",
    "#             file.write(book_response.content)\n",
    "#     else:\n",
    "#         print(f\"Failed to download from {download_url}. Status code: {book_response.status_code}\")\n",
    "# Main function to scrape books\n",
    "def scrape_books_from_authors(start_letter, end_letter):\n",
    "    for letter in range(ord(start_letter), ord(end_letter) + 1):\n",
    "        book_urls = get_book_urls_from_author(chr(letter))\n",
    "        book_urls_b = book_urls\n",
    "        k = 0\n",
    "        for book_url in book_urls_b:\n",
    "            download_book(book_url)\n",
    "            k = k + 1\n",
    "            if k%10 == 0:\n",
    "                print(f'File downloded from : {book_url}, k = {k}')\n",
    "            time.sleep(2)  \n",
    "if __name__ == \"__main__\":\n",
    "    scrape_books_from_authors('s', 'z')  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
